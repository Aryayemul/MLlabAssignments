{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTrWM_mMWoBy",
        "outputId": "9ed8244b-6a03-47be-9d24-044cea07731d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
        "print(\"CUDA Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8Bt6PJYtdwk",
        "outputId": "c4691599-3ff6-4264-9b01-3df13e179c0c"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes\n",
        "!pip install sentence_transformers -q\n",
        "!pip install llama_index -q\n",
        "%pip install llama-index-llms-huggingface\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDYPb8C7jZKw"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader,ServiceContext\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.prompts.prompts import SimpleInputPrompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "G66zjM5rjn-R",
        "outputId": "1dedcd62-3ac3-431a-aa64-65a320a2e975"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "documents = SimpleDirectoryReader(\"./data/scraped\").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "eNiMsmzkj2qT",
        "outputId": "fa3ed1fb-ed6f-4ff1-9cf2-48a6e8d9160f"
      },
      "outputs": [],
      "source": [
        "len(documents), documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4udo5cllF6T"
      },
      "outputs": [],
      "source": [
        "system_prompt=\"\"\"\n",
        "You are a personal Q&A assistant. Your goal is to answer questions as\n",
        "accurately as possible based on the instructions and context provided.\n",
        "\"\"\"\n",
        "## Default format supportable by LLama2\n",
        "query_wrapper_prompt=SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki2Vf_pKZPb5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOSo_mxflKVg"
      },
      "outputs": [],
      "source": [
        "\n",
        "!huggingface-cli login "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LT9yZiX7lMfs"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ukQjeHKla_w"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGkfRsSrlgbu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Manually assign the token (replace with your actual token)\n",
     
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=1024,\n",
        "    generate_kwargs={\"temperature\": 0.8, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"stabilityai/stablelm-zephyr-3b\",\n",
        "    model_name=\"stabilityai/stablelm-zephyr-3b\",\n",
        "    # device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",  # Explicitly set device\n",
        "    device_map=\"balanced\",  # Explicitly set device\n",
        "    model_kwargs={\"torch_dtype\": torch.float16, \"load_in_4bit\": True, 'token': token}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc5U3JnPqWZ7"
      },
      "outputs": [],
      "source": [
        "%pip install llama-index-embeddings-langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvuYtgBPzn7t"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voN0hVRfzX-Y"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "# from llama_index.core import ServiceContext\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "\n",
        "embed_model=LangchainEmbedding(\n",
        "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuNjt5fYzclp"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zrZtUwet0WHn"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.settings import Settings\n",
        "\n",
        "Settings.chunk_size = 1024\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UtDpRSFX0WoJ"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex.from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "O2_VQlpH0icj"
      },
      "outputs": [],
      "source": [
        "query_engine=index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QQDF-F-1BLD"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\"What is the basic salary of a data scientist\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Up9AR4ObR9K"
      },
      "outputs": [],
      "source": [
        "!pip install Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lxlSigZFoLbL"
      },
      "outputs": [],
      "source": [
        "# import gradio as gr\n",
        "# from collections import deque\n",
        "\n",
        "# # Multi-Turn Memory\n",
        "# conversation_history = deque(maxlen=5)\n",
        "\n",
        "# def chatbot(input_text):\n",
        "#     \"\"\"Handles chatbot queries with multi-turn memory.\"\"\"\n",
        "#     conversation_history.append(f\"üë§ User: {input_text}\")\n",
        "#     full_context = \"\\n\".join(conversation_history)\n",
        "\n",
        "#     # Replace this with your actual chatbot response mechanism\n",
        "#     response = query_engine.query(full_context)  # Ensure query_engine is initialized\n",
        "\n",
        "#     conversation_history.append(f\"ü§ñ Assistant: {response}\")\n",
        "    \n",
        "#     # Return formatted conversation\n",
        "#     return \"\\n\\n\".join(conversation_history)\n",
        "\n",
        "# def clear_chat():\n",
        "#     \"\"\"Clears the conversation history.\"\"\"\n",
        "#     conversation_history.clear()\n",
        "#     return \"\"\n",
        "\n",
        "# # Custom CSS for Styling\n",
        "# custom_css = \"\"\"\n",
        "# /* Page background */\n",
        "# /* Page background */\n",
        "# body {\n",
        "#     background-color: #2c2d2f;\n",
        "#     font-family: Arial, sans-serif !important;\n",
        "# }\n",
        "\n",
        "# /* Chatbox styling */\n",
        "# textarea {\n",
        "#     font-size: 16px !important;\n",
        "#     border-radius: 8px !important;\n",
        "#     background: #ffffff !important;\n",
        "#     border: 1px solid #ccc !important;\n",
        "#     padding: 12px !important;\n",
        "#     color: black !important;\n",
        "#     resize: none !important; /* Prevents resizing for better UI */\n",
        "# }\n",
        "\n",
        "# /* User input box */\n",
        "# input[type=\"text\"], textarea {\n",
        "#     color: white !important;\n",
        "#     font-size: 16px !important;\n",
        "#     border-radius: 8px !important;\n",
        "#     border: 1px solid #666 !important;\n",
        "#     padding: 12px !important;\n",
        "#     background: #222222 !important; /* Dark background for contrast */\n",
        "#     transition: all 0.3s ease-in-out !important;\n",
        "# }\n",
        "\n",
        "# /* User input box on focus */\n",
        "# input[type=\"text\"]:focus, textarea:focus {\n",
        "#     border-color: #007bff !important;\n",
        "#     outline: none !important;\n",
        "#     background: #333333 !important;\n",
        "# }\n",
        "\n",
        "# /* Buttons */\n",
        "# button {\n",
        "#     font-size: 16px !important;\n",
        "#     border-radius: 8px !important;\n",
        "#     padding: 12px 18px !important;\n",
        "#     border: none !important;\n",
        "#     cursor: pointer !important;\n",
        "#     font-weight: bold !important;\n",
        "#     text-transform: uppercase !important;\n",
        "#     transition: all 0.3s ease-in-out !important;\n",
        "# }\n",
        "\n",
        "# /* Send button */\n",
        "# button:nth-child(1) {\n",
        "#     background-color: #007bff !important;\n",
        "#     color: white !important;\n",
        "#     box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.2) !important;\n",
        "# }\n",
        "\n",
        "# button:nth-child(1):hover {\n",
        "#     background-color: #0056b3 !important;\n",
        "#     transform: scale(1.05) !important;\n",
        "# }\n",
        "\n",
        "# /* Clear button */\n",
        "# button:nth-child(2) {\n",
        "#     background-color: #dc3545 !important;\n",
        "#     color: white !important;\n",
        "#     box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.2) !important;\n",
        "# }\n",
        "\n",
        "# button:nth-child(2):hover {\n",
        "#     background-color: #a71d2a !important;\n",
        "#     transform: scale(1.05) !important;\n",
        "# }\n",
        "\n",
        "# /* Improved layout and wider spacing */\n",
        "# .gradio-container {\n",
        "#     max-width: 1600px !important; /* Increased width */\n",
        "#     width: 90% !important; /* Make it responsive */\n",
        "#     margin: auto !important;\n",
        "#     padding: 30px !important;\n",
        "#     border-radius: 12px !important;\n",
        "#     background: rgb(35, 34, 34) !important;\n",
        "#     box-shadow: 0px 6px 12px rgba(0, 0, 0, 0.15) !important;\n",
        "# }\n",
        "\n",
        "\n",
        "\n",
        "# \"\"\"\n",
        "\n",
        "# # Gradio UI with Custom CSS\n",
        "# with gr.Blocks(css=custom_css) as demo:\n",
        "#     gr.Markdown(\"# ü§ñ **Smart AI Chatbot**\", elem_id=\"title\")\n",
        "#     gr.Markdown(\"### üí¨ Chat with an intelligent assistant!\", elem_id=\"subtitle\")\n",
        "\n",
        "#     chatbox = gr.Textbox(label=\"Conversation History\", interactive=False, lines=10)\n",
        "#     user_input = gr.Textbox(lines=2, placeholder=\"Type your message...\", label=\"Your Message\")\n",
        "    \n",
        "#     with gr.Row():\n",
        "#         submit_btn = gr.Button(\"üöÄ Send\")\n",
        "#         clear_btn = gr.Button(\"üóëÔ∏è Clear Chat\")\n",
        "\n",
        "#     submit_btn.click(chatbot, inputs=user_input, outputs=chatbox)\n",
        "#     clear_btn.click(clear_chat, outputs=chatbox)\n",
        "\n",
        "# demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP4-mLRUN_ii"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "# Multi-Turn Memory\n",
        "conversation_history = deque(maxlen=5)\n",
        "\n",
        "# Configure headers to mimic browser behavior\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "}\n",
        "\n",
        "# ===== CHATBOT FUNCTIONS =====\n",
        "def chatbot(input_text):\n",
        "    \"\"\"Handles chatbot queries with multi-turn memory.\"\"\"\n",
        "    conversation_history.append(f\"üë§ User: {input_text}\")\n",
        "    full_context = \"\\n\".join(conversation_history)\n",
        "\n",
        "    # Replace this with your actual chatbot response mechanism\n",
        "    try:\n",
        "        response = query_engine.query(full_context)  # Ensure query_engine is initialized\n",
        "    except:\n",
        "        # Fallback if query_engine is not available\n",
        "        response = f\"You said: {input_text}\"\n",
        "\n",
        "    conversation_history.append(f\"ü§ñ Assistant: {response}\\n\")\n",
        "    \n",
        "    # Return formatted conversation with single newlines instead of double\n",
        "    return \"\\n\".join(conversation_history)\n",
        "\n",
        "def clear_chat():\n",
        "    \"\"\"Clears the conversation history.\"\"\"\n",
        "    conversation_history.clear()\n",
        "    return \"\"\n",
        "\n",
        "# ===== LINKEDIN JOB SEARCH FUNCTIONS =====\n",
        "def scrape_linkedin_jobs(query, location=\"\"):\n",
        "    \"\"\"Scrape LinkedIn job listings based on search query\"\"\"\n",
        "    base_url = \"https://www.linkedin.com/jobs/search/\"\n",
        "    params = {\n",
        "        \"keywords\": query,\n",
        "        \"location\": location,\n",
        "        \"position\": 1,\n",
        "        \"pageNum\": 0\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(base_url, params=params, headers=HEADERS)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        \n",
        "        jobs = []\n",
        "        job_listings = soup.find_all('div', class_='base-card')\n",
        "        \n",
        "        for job in job_listings[:10]:  # Limit to 10 results\n",
        "            title = job.find('h3', class_='base-search-card__title').text.strip()\n",
        "            company = job.find('a', class_='hidden-nested-link').text.strip()\n",
        "            job_location = job.find('span', class_='job-search-card__location').text.strip()\n",
        "            link = job.find('a', class_='base-card__full-link')['href']\n",
        "            \n",
        "            jobs.append({\n",
        "                'title': title,\n",
        "                'company': company,\n",
        "                'location': job_location,\n",
        "                'link': link.split('?')[0]  # Clean URL\n",
        "            })\n",
        "            \n",
        "            time.sleep(0.5)  # Be polite with requests\n",
        "            \n",
        "        return jobs\n",
        "    \n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def display_jobs(query, location):\n",
        "    # Validate query to ensure it's job-related\n",
        "    if not is_valid_job_query(query):\n",
        "        return \"<div style='color: #FF6B6B; background-color: rgba(255, 107, 107, 0.1); padding: 15px; border-radius: 10px; border-left: 4px solid #FF6B6B;'><strong>‚ö†Ô∏è Invalid Job Query:</strong> Please enter a valid job title, role, or industry. Examples: 'Software Engineer', 'Data Scientist', 'Marketing', 'Healthcare'.</div>\"\n",
        "    \n",
        "    jobs = scrape_linkedin_jobs(query, location)\n",
        "    \n",
        "    if isinstance(jobs, str):  # Error case\n",
        "        return f\"<div style='color: red'>{jobs}</div>\"\n",
        "    \n",
        "    if not jobs:\n",
        "        return \"<div style='color: orange'>No jobs found for this search.</div>\"\n",
        "    \n",
        "    html_output = f\"<h3>Found {len(jobs)} jobs:</h3>\"\n",
        "    for idx, job in enumerate(jobs, 1):\n",
        "        html_output += f\"\"\"\n",
        "        <div style='margin-bottom: 20px; border-bottom: 1px solid #ccc; padding-bottom: 10px;'>\n",
        "            <h4>{idx}. {job['title']}</h4>\n",
        "            <p><strong>Company:</strong> {job['company']}</p>\n",
        "            <p><strong>Location:</strong> {job['location']}</p>\n",
        "            <p><a href=\"{job['link']}\" target=\"_blank\">View Job</a></p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    return html_output\n",
        "\n",
        "def is_valid_job_query(query):\n",
        "    \"\"\"\n",
        "    Validate if the query appears to be job-related.\n",
        "    Returns True for valid job queries, False otherwise.\n",
        "    \"\"\"\n",
        "    if not query or len(query.strip()) < 2:\n",
        "        return False\n",
        "        \n",
        "    # Common job-related terms/prefixes/suffixes\n",
        "    job_related_terms = [\n",
        "        \"developer\", \"engineer\", \"manager\", \"assistant\", \"specialist\", \"analyst\", \n",
        "        \"designer\", \"consultant\", \"coordinator\", \"director\", \"technician\", \"representative\",\n",
        "        \"administrator\", \"supervisor\", \"officer\", \"programmer\", \"scientist\", \"associate\",\n",
        "        \"intern\", \"job\", \"career\", \"position\", \"role\", \"hiring\", \"recruitment\",\n",
        "        \"full-time\", \"part-time\", \"remote\", \"work\", \"employment\",\n",
        "        # Industries\n",
        "        \"tech\", \"it\", \"software\", \"health\", \"medical\", \"finance\", \"banking\", \"education\",\n",
        "        \"retail\", \"sales\", \"marketing\", \"hr\", \"legal\", \"media\", \"design\", \"construction\",\n",
        "        \"manufacturing\", \"engineering\", \"science\", \"research\", \"data\", \"ai\", \"ml\",\n",
        "        # Roles\n",
        "        \"ceo\", \"cto\", \"cfo\", \"vp\", \"head\", \"lead\", \"junior\", \"senior\", \"mid\", \"staff\"\n",
        "    ]\n",
        "    \n",
        "    query_lower = query.lower()\n",
        "    \n",
        "    # Check if any job-related term is in the query\n",
        "    for term in job_related_terms:\n",
        "        if term in query_lower or query_lower in term:\n",
        "            return True\n",
        "            \n",
        "    # If query is very long, likely not a job search\n",
        "    if len(query_lower) > 50:\n",
        "        return False\n",
        "        \n",
        "    # If query contains question marks or specific non-job phrases\n",
        "    if \"?\" in query or \"who is\" in query_lower or \"what is\" in query_lower or \"how to\" in query_lower:\n",
        "        return False\n",
        "        \n",
        "    # Default to allowing the query if we're not sure\n",
        "    return True\n",
        "\n",
        "# Custom CSS for Styling\n",
        "custom_css = \"\"\"\n",
        "/* Modern Gradient-based Color Scheme */\n",
        ":root {\n",
        "    --primary: #7C4DFF;    /* Deep purple */\n",
        "    --secondary: #2A2E45;  /* Navy blue */\n",
        "    --background: #1A1C28; /* Space black */\n",
        "    --accent: #FF6B6B;     /* Coral pink */\n",
        "    --text: #F0F0FF;       /* Soft lavender */\n",
        "}\n",
        "\n",
        "/* Base Styling with Larger Fonts */\n",
        "body {\n",
        "    font-size: 19px !important;\n",
        "    line-height: 1.7 !important;\n",
        "    background: linear-gradient(135deg, var(--background) 0%, #242736 100%);\n",
        "    font-family: 'Inter', system-ui, sans-serif;\n",
        "    color: var(--text) !important;\n",
        "}\n",
        "\n",
        "/* Text Elements Scaling */\n",
        "h1 { font-size: 2.8rem !important; }\n",
        "h2 { font-size: 2.2rem !important; }\n",
        "h3 { font-size: 1.9rem !important; }\n",
        "p { font-size: 1.1em !important; }\n",
        "\n",
        "/* Chat Interface */\n",
        ".gr-box {\n",
        "    background: rgba(42, 46, 69, 0.85) !important;\n",
        "    backdrop-filter: blur(12px);\n",
        "    border-radius: 18px;\n",
        "    border: 1px solid rgba(124, 77, 255, 0.25);\n",
        "    font-size: 1.15rem !important;\n",
        "}\n",
        "\n",
        "/* Reduced gap between buttons */\n",
        ".button-row {\n",
        "    gap: 5px !important;\n",
        "}\n",
        "\n",
        "/* Conversation text spacing */\n",
        ".gr-textbox span {\n",
        "    line-height: 1.4 !important;\n",
        "    margin-bottom: 0.3rem !important;\n",
        "}\n",
        "\n",
        "/* Chat display customization */\n",
        "#chat-display {\n",
        "    padding: 8px !important;\n",
        "    margin-bottom: 10px !important;\n",
        "}\n",
        "\n",
        "#chat-display textarea {\n",
        "    line-height: 1.3 !important;\n",
        "}\n",
        "\n",
        "/* Input Fields */\n",
        "input[type=\"text\"], textarea {\n",
        "    font-size: 1.2rem !important;\n",
        "    padding: 18px !important;\n",
        "    background: rgba(255, 255, 255, 0.08) !important;\n",
        "    border: 2px solid rgba(124, 77, 255, 0.3) !important;\n",
        "}\n",
        "\n",
        "/* Buttons */\n",
        "button {\n",
        "    font-size: 1.25rem !important;\n",
        "    padding: 16px 28px !important;\n",
        "    background-image: linear-gradient(135deg, var(--primary) 0%, #906BFF 100%) !important;\n",
        "    border-radius: 14px !important;\n",
        "}\n",
        "\n",
        "button:hover {\n",
        "    transform: translateY(-2px) scale(1.02);\n",
        "    box-shadow: 0 10px 20px rgba(124, 77, 255, 0.25) !important;\n",
        "}\n",
        "\n",
        "/* Job Listings */\n",
        ".job-card {\n",
        "    background: linear-gradient(145deg, #2A2E45 0%, #1F2235 100%);\n",
        "    border-radius: 16px;\n",
        "    padding: 24px;\n",
        "    font-size: 1.1rem !important;\n",
        "}\n",
        "\n",
        ".job-card h4 {\n",
        "    font-size: 1.5rem !important;\n",
        "    background: linear-gradient(45deg, var(--primary), var(--accent));\n",
        "    -webkit-background-clip: text;\n",
        "    -webkit-text-fill-color: transparent;\n",
        "}\n",
        "\n",
        "/* Chat History */\n",
        "#chat-history {\n",
        "    font-size: 1.2rem !important;\n",
        "    line-height: 1.8 !important;\n",
        "    padding: 24px !important;\n",
        "}\n",
        "\n",
        "/* Interactive Elements */\n",
        ".gr-textbox:focus, button:focus {\n",
        "    box-shadow: 0 0 0 4px rgba(124, 77, 255, 0.3) !important;\n",
        "}\n",
        "\n",
        "/* Scrollbar */\n",
        "::-webkit-scrollbar {\n",
        "    width: 10px;\n",
        "    background: var(--secondary);\n",
        "}\n",
        "\n",
        "::-webkit-scrollbar-thumb {\n",
        "    background: linear-gradient(var(--primary), var(--accent));\n",
        "    border-radius: 6px;\n",
        "}\n",
        "\n",
        "/* Section Dividers */\n",
        ".section-divider {\n",
        "    height: 4px;\n",
        "    background: linear-gradient(90deg, transparent 0%, var(--primary) 50%, transparent 100%);\n",
        "    margin: 2.5rem 0;\n",
        "}\n",
        "\n",
        "/* Status Messages */\n",
        ".gr-label {\n",
        "    font-size: 1.3rem !important;\n",
        "    letter-spacing: 0.5px;\n",
        "}\n",
        "\n",
        "/* Responsive Scaling */\n",
        "@media (max-width: 768px) {\n",
        "    body { font-size: 17px !important; }\n",
        "    h1 { font-size: 2.2rem !important; }\n",
        "    button { font-size: 1.1rem !important; }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create the combined Gradio interface\n",
        "with gr.Blocks(css=custom_css, title=\"AI Assistant with Job Search\") as demo:\n",
        "    gr.Markdown(\"# ü§ñ **Smart AI Chatbot **\", elem_id=\"title\")\n",
        "    \n",
        "    # Chatbot Section (Top)\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"### üí¨ Chat with an intelligent assistant!\", elem_id=\"subtitle\")\n",
        "        \n",
        "        chatbox = gr.Textbox(label=\"Conversation History\", interactive=False, lines=12, elem_id=\"chat-display\")\n",
        "        user_input = gr.Textbox(lines=1, placeholder=\"Type your message...\", label=\"Your Message\")\n",
        "        \n",
        "        with gr.Row(elem_classes=[\"button-row\"]):\n",
        "            submit_btn = gr.Button(\"üöÄ Send\")\n",
        "            clear_btn = gr.Button(\"üóëÔ∏è Clear Chat\")\n",
        "\n",
        "        submit_btn.click(fn=chatbot, inputs=user_input, outputs=chatbox)\n",
        "        user_input.submit(fn=chatbot, inputs=user_input, outputs=chatbox)\n",
        "        clear_btn.click(fn=clear_chat, outputs=chatbox)\n",
        "    \n",
        "    # Divider\n",
        "    gr.Markdown(\"---\", elem_id=\"divider\", elem_classes=[\"section-divider\"])\n",
        "    \n",
        "    # LinkedIn Job Search Section (Bottom)\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"## üîç LinkedIn Job Search\", elem_id=\"subtitle\")\n",
        "        gr.Markdown(\"Enter your job search query below:\")\n",
        "        \n",
        "        with gr.Row():\n",
        "            job_query = gr.Textbox(label=\"Job title or keywords\", placeholder=\"Software Engineer\")\n",
        "            job_location = gr.Textbox(label=\"Location (optional)\", placeholder=\"New York\")\n",
        "        \n",
        "        search_btn = gr.Button(\"üîç Search Jobs\")\n",
        "        \n",
        "        job_output = gr.HTML()\n",
        "        \n",
        "        search_btn.click(\n",
        "            fn=display_jobs,\n",
        "            inputs=[job_query, job_location],\n",
        "            outputs=job_output,\n",
        "        )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
